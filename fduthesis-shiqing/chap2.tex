\chapter{相关工作与理论}
\section{引言}
本章从不确定性的建模方法，不确定性的计算，不确定性建模方法的评估等三个角度介绍不确定性的相关理论和研究工作。最近几年关于不确定性的建模方法兴起了许多不同的思路，从单个神经网络建模到集成多个模型建模，从神经网络权重参数确定到神经网络权重参数符合某个分布。关于神经网络的不确定性的计算，是指给定某种建模思路，如何计算出一个标量表示不确定性。一些计算方法把神经网络的数据不确定性和模型不确定性分开，一些方法则不分开。由于大多数情况下，神经网络的不确定性是缺乏标签信息的，所以没办法直接评估一种建模思路计算出的不确定性的好坏，只能通过一些代理任务上的表现，来间接地反映建模方法的好坏。下面从这三个方面依次论述。

\section{不确定性的建模方法}
目前，在神经网络不确定性的研究上，提出了许多建模方法：
\begin{itemize}
    \item 贝叶斯神经网络：通过在神经网络中引入贝叶斯推断，建模权重参数的不确定性，从而获得模型的输出不确定性。
    \item Ensemble的方法：通过训练多个神经网络，对于同一个输入，可以得到多个预测结果，进而通过计算多个预测值的方差或者熵来建模不确定性
    \item Test Time Augmentation的方法：通过对输入做数据增强，得到多个增强后的输入，然后进入训练好的神经网络中预测多次得到多个预测结果，进而计算模型输出的不确定性。
    \item 单一确定的神经网络来建模不确定性：这类方法使用单一确定性的神经网络建模不确定性
\end{itemize}

\subsection{贝叶斯神经网络}
贝叶斯神经网络是一种将贝叶斯统计方法与深度学习相结合的模型，通过对神经网络的参数引入概率分布，量化模型的不确定性。 在传统神经网络中，参数（权重和偏置）是固定值；而在贝叶斯神经网络中，如图2-1,参数被视为随机变量，遵循某种概率分布（如高斯分布）。这种方法使模型输出不仅仅是一个确定值，而是一个分布，从而反映模型的置信程度。贝叶斯神经网络加建模不确定性的基本思路如下。

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\linewidth]{assets/2-1.png}
    \caption{贝叶斯神经网络\cite{blundell2015weight}
}
    \label{fig:enter-label}
\end{figure}


\begin{itemize}
    \item \textbf{贝叶斯推断}：
    通过贝叶斯公式来求解参数分布：
    \[
    P(\theta \mid \mathcal{D}) = \frac{P(\mathcal{D} \mid \theta) P(\theta)}{P(\mathcal{D})}
    \]
    其中：
    \begin{itemize}
        \item \( P(\theta \mid \mathcal{D}) \)：后验分布（目标分布）。
        \item \( P(\mathcal{D} \mid \theta) \)：似然函数（数据生成概率）。
        \item \( P(\theta) \)：先验分布（参数的初始假设）。
        \item \( P(\mathcal{D}) \)：边际似然，用于归一化。
    \end{itemize}
    
    \item \textbf{输出分布}：
    当输入图片到贝叶斯神经网络里预测时，输出的不是单一值，而是一个分布。从关于参数的后验分\( P(\theta \mid \mathcal{D}) \)采样多个 \( \theta \)，通过这些 \( \theta \) 计算多个 \( y \)，对 \( y \) 进行汇总（如计算熵或方差）得到不确定性。
\end{itemize}

贝叶斯神经网络的难题是后验分布 \( P(\theta \mid \mathcal{D}) \) 的估计。由于直接计算后验分布 \( P(\theta \mid \mathcal{D}) \) 通常是不可行的，贝叶斯神经网络采用近似方法，通常的近似手段有采样(如马尔科夫链蒙特卡罗方法），变分推断，拉普拉斯近似等几种。马尔科夫链蒙特卡罗（MCMC）方法是一种通过随机抽样来逼近后验分布的方法。常见的 MCMC 算法包括 Metropolis-Hastings 算法和 Gibbs 采样。它们通过生成一系列样本来估计后验分布，但计算开销较大，尤其是在高维参数空间中。变分推断通过将后验分布近似为一个简单的分布族（例如高斯分布）来进行推断。它通过最小化某种距离度量（如 Kullback-Leibler 散度）来优化参数，使得近似分布尽可能接近真实的后验分布。变分推断通常计算更高效，适用于大规模数据集。：拉普拉斯近似通过在后验分布的最大后验估计（MAP）附近用二次泰勒展开来近似后验分布。该方法对于参数空间较小或者后验分布接近高斯分布的情况特别有效。Charles Blundell\cite{blundell2015weight}等人提出了Bayes By Backprob算法高效第计算权重参数的后验分布。Yarin Gal\cite{gal2016dropout}等人提出了MC Dropout的方法来近似。这种方法在预测阶段保留 Dropout，并通过多次前向传播获得样本分布，是一种近似贝叶斯推断的实用方法。 Hippolyt Ritter\cite{ritter2018scalable}等人通过构建  Kronecker分解的拉普拉斯近似，近似求解权重参数的后验分布。Welling等人\cite{welling2011bayesian}提出了一种称为 Stochastic Gradient Langevin Dynamics (SGLD) 的方法，结合了随机梯度下降 (SGD) 和 Langevin 动力学的思想，用随机梯度近似后验分布，同时引入噪声来模仿MCMC采样过程。



\subsection{Ensemble的方法}
集成（Ensemble）方法\cite{lakshminarayanan2017simple}是一种通过结合多个模型的预测来提高性能和鲁棒性的技术。在建模不确定性时，集成方法的核心思想是通过多个独立模型的多样性来量化预测结果的可信度。以下是关于使用集成方法建模不确定性的详细说明。集成方法训练多个独立的模型，每个模型从不同的角度对数据进行学习。通过将这些模型的预测结果进行组合（例如取平均），可以提高整体的预测性能并提供不确定性估计。以下是Ensemble类方法的建模步骤:


\begin{enumerate}
    \item \textbf{训练多个模型}：
    训练 \( M \) 个独立的神经网络模型 \( f_1(x), f_2(x), \ldots, f_M(x) \)，其中每个模型的参数初始化不同，或者使用不同的训练数据子集（如 Bagging 方法）。

    \item \textbf{预测分布}：
    对于给定输入 \( x \)，每个模型生成一个预测 \( y_i = f_i(x) \)。集成方法的预测分布可以通过这些独立模型的输出构造， 通过汇总预测分布的统计量（如方差、熵）来评估不确定性。
    \[
    P(y \mid x) \approx \frac{1}{M} \sum_{i=1}^M P(y \mid f_i(x))
    \]
\end{enumerate}

Y Wen\cite{wen2020batchensemble}等人提出BatchEnsemble解决Ensemble方法需要训练多个模型的存储和计算复杂度，BatchEnsemble 将一个大模型分解为多个小模型，每个小模型具有自己的参数化方式，但它们共享同一个主干模型的参数。通过共享基础权重 W，BatchEnsemble 避免了传统ensemble方法中每个模型都需要独立存储全部参数的缺点。BatchEnsemble 大大减少了内存占用和计算需求。




\subsection{Test Time Augmentation的方法}
Test Time Agmentation(测试时数据增强，TTA)的方法是一种通过对测试数据应用多种数据增强方式来估计模型预测不确定性的方法。该方法通过将同一输入的不同增强版本的预测结果进行汇总，量化模型对该输入的置信程度。


\begin{enumerate}
    \item \textbf{数据增强}：
    对测试数据 \( x \)，应用一系列数据增强操作 \( T_1, T_2, \ldots, T_N \)，生成多个增强版本 \( \{ T_i(x) \}_{i=1}^N \)。

    \item \textbf{预测分布}：
    对每个增强版本，模型 \( f \) 生成对应的预测结果 \( \{ f(T_i(x)) \}_{i=1}^N \)。这些预测结果的分布可以反映模型的不确定性。
    通过汇总预测分布的统计量（如方差、熵）来评估不确定性。
\end{enumerate}

在TTA的建模方法中，一个重要的问题是如何选择有效的数据增强方式。Divya Shanmugam等人\cite{shanmugam2020and}探讨了如何选择合适的增强策略，以及在结果聚合（如简单平均、加权平均）中的设计方法。




\subsection{单一确定性神经网络建模}
还有很重要的一类建模不确定性的方法是使用单一确定性的网络进行建模。所谓单一确定神经网络，这里的单一是指只需要训练一个神经网络，不像Ensemble类方法需要训练多个网络；这里的确定是指网络参数是确定的，不像贝叶斯神经网络一样符合某个分布。这类方法建模不确定性通常直接从单一确定性模型的输出中直接推导出不确定性。这类方法通过模型结构或损失函数设计，使模型能够在不需要多模型或参数采样的情况下提供对不确定性的量化，从而降低计算和存储成本。单一确定神经网络可以分为Internal Methods和Externel Methods\cite{gawlikowski2023survey}。

Internal Methods是指不使用额外的头去预测不确定性，不确定性的计算和原有神经网络的预测是一起的。这类方法中，Prior Network\cite{malinin2018predictive} 通过引入一个显式的先验分布来对分类问题中的不确定性建模。这种方法使用一个神经网络直接对分类器的分布进行建模，而不是仅输出点估计。Prior Network 的输出是一个分类概率分布的参数，例如 Dirichlet 分布的参数$\alpha$，用以表征预测的不确定性。Murat Sensoy等人\cite{sensoy2018evidential}提出了一个新方法，通过引入主观逻辑理论，在神经网络的分类概率上使用狄利克雷分布来量化不确定性。该方法将神经网络的分类结果视为主观意见，网络学习如何根据数据收集证据来支持每个类别的预测。这种方法不仅能预测分类结果，还能量化预测的不确定性，从而提升模型的鲁棒性，特别是在面对对抗样本和分布外数据时。
深度核学习（Deep Kernel Learning）\cite{van2021feature}结合深度神经网络和高斯过程，将神经网络的输出作为核函数的输入，捕捉数据的不确定性。

Internal Methods中，一种经常作为不确定性领域Baseline的方法是使用最大预测概率\cite{hendrycks2017a}(Maximum Softmax Probability, MSP)作为不确定性的度量。作者观察到，OOD 样本的MSP值通常会低于inD样本。因此可以使用MSP来建模不确定性。当分类器遇到ID样本时，输出的类概率高 (置信度高) ，遇到OOD样本时，输出的概率虽然比较高。MSP优点是简单易实现，直接利用现有神经网络的 softmax 输出，无需修改网络架构或增加额外的训练开销。MSP 的计算仅需一次前向传播，非常适合实时场景。缺点是如果分布内数据和分布外数据在特征空间上高度重叠，MSP 的建模不确定性的能力可能不足。DUQ\cite{van2020uncertainty}通过使用与径向基函数（RBF）的结构，训练一个可以在推理时通过一次前向传播计算不确定性的模型。SNGP\cite{liu2020simple}核心思想是引入输入距离感知，即模型能够量化测试样本与训练数据之间的距离，从而准确评估预测的不确定性。为了实现这一点，论文提出了谱归一化神经高斯过程（SNGP），通过在训练中加入权重归一化步骤和替换倒数第二层的激活函数来增强模型的距离感知能力。
论文\cite{charpentier2023training}探讨了对于单一确定性的神经网络，不确定性的建模和神经网络架构和训练方式的关系。

Externel Methods显式地在原有模型基础上额外添加一个头来预测不确定性。Maithra Raghu等人\cite{raghu2019direct}提出了一种直接不确定性预测（Direct Uncertainty Prediction, DUP）方法，通过神经网络直接预测医学诊断任务中的预测置信度。由于不确定性标注的困难性，关于这类建模不确定性方法很少。


\subsection{以上主流方法的对比}
下面对比以上列举的四类建模不确定性方法的优缺点。

贝叶斯神经网络建模不确定性具有以下优点：1.良好的可解释性，有非常好的数学基础。2.通过对参数的概率建模，BNN天然具有正则化效果。3.在数据较少时，先验分布能提供有用的信息，提高模型的性能。4.对输入噪声或异常值有更高的鲁棒性。贝叶斯神经网络建模不确定性具有以下挑战和局限：1.参数分布的推断和采样导致计算复杂度远高于传统神经网络。2.随着网络规模的增加，推断过程可能变得难以处理。3.先验分布的选择对模型性能有重要影响，但通常难以确定。4.变分推断或 MCMC 方法训练困难，可能收敛缓慢，需要调整超参数。


基于Enseble建模不确定性的方法有以下优点：1.集成方法通过多模型组合降低单个模型的过拟合风险，提供更可靠的预测。2.集成方法不需要对现有模型结构进行修改，适合与各种神经网络架构结合。基于Enseble建模不确定性的方法有以下局限性：1.训练多个模型会显著增加计算资源需求，尤其是在深度学习场景中。2.每个模型都需要存储其独立的参数，这可能导致较高的存储需求。3.集成效果高度依赖于各个模型的多样性和质量。如果模型过于相似，集成方法的优势可能难以体现。

TTA建模不确定性的优点是:简单易实现，无需修改模型结构或训练过程，直接利用测试阶段的增强技术即可。TTA建模不确定性的缺点是:1.需要对同一输入进行多次推理，增加推理时间。2.不同的增强策略可能导致不确定性估计的效果差异，需要精心设计数据增强方式。


单一确定网络建模不确定性的方法具有以下优点:1.高效的建模方法，不需要多次采样或集成多个模型，推理速度快，计算成本低，高效。2.仅通过设计输出和损失函数即可实现，易于与现有的神经网络框架结合。单一确定网络建模不确定性的方法具有以下局限性：模型输出的分布假设（如高斯分布）可能无法充分建模复杂数据的分布，导致不确定性的建模效果不好。

\section{不确定性的计算方法}
针对不同的建模不确定性的方法，对不确定性的计算在各不相同。在分类任务上和回归任务上，对于不确定性的计算也不相同。有的关于不确定性的计算区分开模型不确定性和数据不确定性，有的则不分开，只计算总的预测不确定性。以下列举几种常见情况下不确定性的计算公式。

\subsection{分类任务中不确定性的计算}

\textbf{预测概率的不确定性}:对于每个分类任务，模型输出每个类别的预测概率。模型的不确定性可以通过评估这些预测概率的分布来衡量。常见的计算方法包括：最大概率法
    \[
    P_{\text{max}} = \max_{i} P(y_i | \mathbf{x})
    \]
    其中，\( P(y_i | \mathbf{x}) \) 是模型对样本 \( \mathbf{x} \) 的类别 \( y_i \) 的预测概率。最大概率 \( P_{\text{max}} \) 越接近1，表示模型的确定性越高；越接近0.5（对于二分类任务），表示不确定性较高。


\textbf{熵（Entropy)}:熵是衡量概率分布不确定性的标准方法。对于分类任务，熵的计算公式为：
\[
H(\mathbf{x}) = - \sum_{i=1}^{C} P(y_i | \mathbf{x}) \log P(y_i | \mathbf{x})
\]
其中，\( C \) 是类别数，\( P(y_i | \mathbf{x}) \) 是样本 \( \mathbf{x} \) 被预测为类别 \( y_i \) 的概率。熵越大，表示模型对样本的分类越不确定。

\textbf{方差（Variance）}:对于多个模型预测或多次模型预测，可以使用预测方差来衡量不确定性：
\[
\text{Var}(\mathbf{x}) = \frac{1}{T} \sum_{t=1}^{T} \left( P_t(y | \mathbf{x}) - \bar{P}(\mathbf{x}) \right)^2
\]
其中，\( T \) 是模型预测的次数，\( P_t(y | \mathbf{x}) \) 是第 \( t \) 次预测的概率，\( \bar{P}(\mathbf{x}) \) 是所有预测概率的平均值。

\textbf{互信息（Mutual Information）}:互信息衡量了输入特征与输出类别之间的信息共享量。在分类任务中，输入特征 \( \mathbf{x} \) 和输出类别 \( y \) 之间的互信息可以计算为：
\[
I(\mathbf{x}; y) = H(y) - H(y | \mathbf{x})
\]
其中，\( H(y) \) 是类别 \( y \) 的熵，表示输出的总体不确定性，\( H(y | \mathbf{x}) \) 是在给定输入 \( \mathbf{x} \) 的条件下，类别 \( y \) 的条件熵，表示输入特征给出的信息后，输出类别的剩余不确定性。互信息越大，表示输入特征与输出类别之间的关系越强，从而模型的预测不确定性越小。

互信息也可以用联合概率分布表示：
\[
I(\mathbf{x}; y) = \sum_{i=1}^{C} \sum_{j=1}^{N} P(y_i, \mathbf{x}_j) \log \frac{P(y_i, \mathbf{x}_j)}{P(y_i) P(\mathbf{x}_j)}
\]
其中，\( P(y_i, \mathbf{x}_j) \) 是类别 \( y_i \) 和输入特征 \( \mathbf{x}_j \) 的联合概率分布，\( P(y_i) \) 和 \( P(\mathbf{x}_j) \) 分别是类别和输入特征的边际概率分布。



\subsection{回归任务中不确定性的计算}
\textbf{方差}:对于回归任务，预测方差表示模型预测的不确定性。假设有多个模型的预测结果或多个预测实例，可以计算预测的方差：
\[
\text{Var}(\hat{y} | \mathbf{x}) = \frac{1}{T} \sum_{t=1}^{T} \left( y^{(t)} - \bar{y} \right)^2
\]
其中，\( \bar{y} = \frac{1}{T} \sum_{t=1}^{T} y^{(t)} \) 是预测值的均值，\( T \) 是预测次数。方差越大，模型预测的不确定性越高。

\textbf{置信区间}:置信区间表示模型预测值的上下限：
\[
[\hat{y} - \delta, \hat{y} + \delta]
\]
其中，\( \delta \) 是不确定性的度量（如标准差）。较大的 \( \delta \) 表示较高的不确定性。

\textbf{熵（Entropy）}:回归任务中的熵可以衡量模型预测结果的分布情况。如果误差假设为正态分布，熵的计算公式为：
\[
H(\hat{y}) = \frac{1}{2} \log (2\pi e \sigma^2)
\]
其中，\( \sigma^2 \) 是预测的方差。


\section{不确定性建模的评估}
近年来，随着不确定性建模方法的不断涌现，对这些方法的评估也显得尤为重要。由于大多数不确定性任务难以直接标注不确定性（即无法获得不确定性的 \textit{ground truth}），研究中普遍采用间接方式在代理任务上进行评估。常见的代理任务包括 \textbf{OOD 检测}、\textbf{误分类检测}、\textbf{对抗样本检测} 和 \textbf{主动学习}。以下对每个任务进行详细说明。

\subsection{OOD 检测（Out-of-Distribution Detection）}

OOD 检测任务的目标是在测试过程中识别出那些来自训练集分布外的样本。OOD 样本通常与训练数据的分布显著不同。理想情况下，好的不确定性建模方法应该对 OOD 样本表现出高不确定性。在使用OOD检测任务评估不确定性建模方法的过程中，使用来自训练分布的数据集(如Cifar10)作为正样本（In-Distribution, InD），来自训练集分布外的数据集（如 SVHN, LSUN）的样本作为 OOD 样本，对OOD样本和InD样本分别计算不确定性，如果计算出来的不确定性对于OOD样本和InD样本区分性比较好，那么这种不确定性建模方法就是更好的。从这个角度上来看，不确定性建模的好坏和OOD检测任务是一致的。为了度量计算出的不确定性在区分OOD样本和InD样本的好坏，通常使用机器学习中AUROC，AUPRC，FP95等指标

AUROC，全称Area Under the Receiver Operating Characteristic Curve，即接收者操作特征曲线下面积，是一种衡量二分类模型性能的指标。首先，定义以下几个概念：
\begin{itemize}
    \item \textbf{真阳性率 (True Positive Rate, TPR)}：
    \[
    \text{TPR} = \frac{\text{TP}}{\text{TP} + \text{FN}}
    \]
    其中，\(\text{TP}\) 是真正例数，\(\text{FN}\) 是假反例数。
    
    \item \textbf{假阳性率 (False Positive Rate, FPR)}：
    \[
    \text{FPR} = \frac{\text{FP}}{\text{FP} + \text{TN}}
    \]
    其中，\(\text{FP}\) 是假正例数，\(\text{TN}\) 是真反例数。
\end{itemize}

ROC 曲线是通过改变分类阈值来绘制的，横轴为 FPR，纵轴为 TPR。AUROC 是 ROC 曲线下的面积，定义为：
当 \(\text{AUROC} = 0.5\) 时，模型没有任何区分能力，表现与随机猜测相同。
当 \(\text{AUROC} = 1.0\) 时，模型能够完美区分正负类。
当 \(0.5 < \text{AUROC} < 1.0\) 时，模型具有一定的区分能力，值越大表示性能越好。AUROC 是一个不依赖于特定分类阈值的评估指标，尤其适合于不平衡数据集的情况。

AUPRC 是评估分类模型性能的另一个常用指标，表示精度-召回率曲线下的面积。
首先，定义以下几个概念：

\textbf{精度 (Precision)}：
    \[
    \text{Precision} = \frac{\text{TP}}{\text{TP} + \text{FP}}
    \]
    其中，\(\text{TP}\) 是真正例数，\(\text{FP}\) 是假正例数。
    
\textbf{召回率 (Recall)}：
    \[
    \text{Recall} = \frac{\text{TP}}{\text{TP} + \text{FN}}
    \]
    其中，\(\text{TP}\) 是真正例数，\(\text{FN}\) 是假反例数。


Precision-Recall曲线展示了不同分类阈值下的精度与召回率之间的关系。AUPRC 是该曲线下的面积。
当 \(\text{AUPRC} = 0\) 时，模型完全没有区分能力。
当 \(\text{AUPRC} = 1.0\) 时，模型在所有召回率下的精度都为 1，表示模型完美区分正负类。
当 \(0 < \text{AUPRC} < 1.0\) 时，模型具有一定的区分能力，AUPRC 值越大表示性能越好。
AUPRC 尤其适用于不平衡数据集的情况，因为它直接衡量了在正类样本较少时的分类性能。




\subsection{误分类检测（Misclassification Detection）}


误分类检测的目标是利用对预测结果计算出的不确定性信息识别模型预测错误的样本。理想情况下，模型应对误分类样本表现出高不确定性。使用误分类检测作为代理任务，通过分析模型在测试数据上的误分类样本，观察不确定性分布是否能有效区分正确分类与错误分类的样本,判断不确定性建模算法的好坏。除了包括与OOD 检测类似的常用指标AUROC 和 AUPRC。还有\textbf{Expected Calibration Error (ECE)},衡量模型预测置信度与实际准确率的偏差。Expected Calibration Error (ECE) 是衡量分类模型输出概率与实际标签一致性的一个指标。一个校准良好的模型，其预测概率应当与实际结果的发生频率一致。具体地，若模型预测概率为 \( p \)，那么在长期实验中，模型预测为 \( p \) 的样本中，有 \( p \) 的比例应该属于正类。下面是ECE的计算方法:


1. 分组：
   将预测概率 \( p \) 分成若干个区间，例如：
   \[
   [0, 0.1), [0.1, 0.2), \dots, [0.9, 1.0]
   \]
   这些区间可以根据需要调整。

2. 计算每个区间的校准误差：
   对于第 \( k \) 个区间 \( [p_k, p_{k+1}) \)，计算该区间内所有样本的平均预测概率 \( \hat{p}_k \) 和真实标签的正确率 \( \text{accuracy}_k \)：
   \[
   \hat{p}_k = \frac{1}{|S_k|} \sum_{i \in S_k} p_i
   \]
   \[
   \text{accuracy}_k = \frac{1}{|S_k|} \sum_{i \in S_k} y_i
   \]
   其中，\( S_k \) 是属于第 \( k \) 个区间的样本集合，\( p_i \) 是样本 \( i \) 的预测概率，\( y_i \) 是样本 \( i \) 的真实标签。

3. 计算校准误差：
   对于每个区间，计算其校准误差：
   \[
   \text{ECE}_k = | \hat{p}_k - \text{accuracy}_k |
   \]
   然后，计算所有区间的加权平均值：
   \[
   \text{ECE} = \sum_k \frac{|S_k|}{N} \text{ECE}_k
   \]
   其中，\( N \) 是样本总数，\( |S_k| \) 是第 \( k \) 区间内样本的数量。


当 \(\text{ECE} = 0\) 时，表示模型是完全校准的，预测概率与实际频率完全一致。当 \(\text{ECE}\) 较大时，表示模型存在较大的校准误差，其概率输出与实际标签的匹配不佳。





\subsection{对抗样本检测（Adversarial Example Detection）}

对抗样本检测的目标是识别经过精心设计以欺骗模型的样本。理想情况下，模型对对抗样本的预测应表现出更高的不确定性。

首先使用一定的攻击算法生成一批对抗样本（如 FGSM 或 PGD 攻击），然并与正常样本一起输入模型计算不确定性，检测不确定性是否能区分对抗样本与正常样本。衡量指标与 OOD 检测相同，主要使用 AUROC 和 AUPRC 来评估。


\subsection{主动学习（Active Learning）}


在有限标注预算下，主动学习通过选择具有高不确定性的样本来优化标注数据集的选择策略。一个好的不确定性建模方法应能快速有效挑选提升模型性能的样本。通过迭代方式模拟主动学习过程，每轮根据不确定性选择样本进行标注，在固定训练样本规模下，通过主动学习策略挑选的样本训练模型，观察训练后的性能提升，如果依照不确定性挑选的样本能以较少标注样本达到目标性能，这种不确定性建模方法是良好的。
主动学习是一种机器学习方法，其中模型通过选择最具信息量的样本进行标注，以便在最少的标注成本下获得最大的学习效果。与传统的监督学习不同，主动学习不依赖于全部标注数据，而是通过一个学习算法主动选择样本，从而最大化模型的性能。


主动学习评估不确定性建模方法的基本工作流程如下：

\begin{enumerate}
    \item \textbf{初始化数据集}：首先从未标注的数据池中随机选择一小部分样本，并对这些样本进行标注，构成初始训练集。
    \item \textbf{模型训练}：使用初始训练集训练模型。
    \item \textbf{选择样本}：根据模型的当前性能，从未标注数据池中选择最能提高模型性能的样本。选择策略是依据不确定性采样，从候选池中选择模型最不确定的样本进行标注。
    \item \textbf{标注和迭代}：对选择的样本进行标注，加入到训练集中，然后重新训练模型。重复选择样本和训练的过程，直到满足某个停止条件（例如，达到一定的精度或标注次数）。
\end{enumerate}


\section{本章小结}
本章主要围绕不确定性的研究工作与理论展开讨论，分别从不确定性的建模方法、计算方法以及评估方法三个角度进行阐述。首先，介绍了几类主流的不确定性建模方法，包括贝叶斯神经网络、集成方法（Ensemble）、测试时数据增强（TTA）方法以及单一确定性神经网络，并详细对比了它们在优缺点、适用场景及计算复杂度上的异同。其次，探讨了分类与回归任务中不确定性计算的具体方式，例如基于Softmax输出的预测熵、MC Dropout的熵分解及贝叶斯推断方法的应用等。最后，指出由于标签信息的缺乏，模型的不确定性评估多依赖代理任务的表现，而非直接评估方法。整章通过细致分析总结了不确定性建模领域的重要研究进展与挑战，为后续工作奠定了理论基础。

