\chapter{总结与展望}
\section{总结与反思}
% 本文研究内容主要是基于高维特征概率密度建模神经网络的模型不确定性。前两章主要围绕不确定性的研究工作与理论展开讨论，分别从不确定性的建模方法、计算方法以及评估方法三个角度进行阐述。首先，介绍了几类主流的不确定性建模方法，包括贝叶斯神经网络、集成方法、测试时数据增强方法以及单一确定性神经网络方法，并详细对比了它们在优缺点、适用场景及计算复杂度上的异同。其次，探讨了分类与回归任务中不确定性计算的具体方式，例如基于Softmax输出的预测熵、MC Dropout的熵分解及贝叶斯推断方法的应用等。最后，指出由于标签信息的缺乏，模型的不确定性评估多依赖代理任务的表现，而非直接评估方法。

% 第三章在高维特征概率密度建模的基础上，提出了一种基于输入扰动的改进方法，用于提升模型不确定性量化的能力。研究发现，样本的不确定性与梯度空间的响应具有显著相关性，OOD样本在梯度空间中的响应普遍较高，而训练集样本的响应相对较低。这一发现启发通过输入扰动来增强特征分布的捕捉能力。通过将梯度信息与概率密度建模相结合，该方法不仅为神经网络不确定性量化提供了新的思路，也为实际应用中模型的可靠性提升奠定了基础。然而，输入扰动方法的效果在一定程度上依赖于超参数的选择以及具体的数据分布特性。因此，未来工作可以进一步探讨自适应的扰动生成机制，以实现更为通用且稳健的不确定性建模方法。此外，可以尝试将本章方法与其他先进技术相结合，进一步挖掘梯度空间与特征分布的潜在关联，为神经网络的解释性与鲁棒性研究提供更有力的支持。不同类型的扰动如何影响特征分布，以及扰动对模型学习过程的长期影响，这些问题仍待深入探讨。

% 第四章主要研究了基于特征空间优化的神经网络不确定性建模方法，旨在提升分类性能和预测可靠性。通过引入度量学习技术和提出创新辅助损失函数AuxLoss，优化了特征空间的类内紧密性和类间可分性，有效增强了模型在不同任务中的适应能力与鲁棒性。此外，通过结合PCA降维和高斯判别分析模型，解决了高维数据的存储复杂性问题，实现了高效的不确定性量化。这些方法在MNIST和CIFAR-10等数据集上的实验验证表明，AuxLoss显著提升了模型的分类性能和特征分布质量，而PCA和GDA结合策略进一步提高了计算效率和存储性能。尽管如此，本研究在高维多模态数据、实时计算优化和理论机制深化等方面仍存在进一步探索的空间。未来工作可致力于设计更加自适应的损失函数，以应对复杂任务中的动态变化；在计算效率方面，可结合随机投影、稀疏建模或硬件加速技术，优化高维数据处理流程；此外，针对多模态场景，可以研究特征融合优化策略，从而提升模型在跨领域任务中的通用性与可靠性。同时，通过与输入扰动、对抗训练等方法的结合，进一步完善模型的不确定性建模体系。在理论方面，可基于信息论或概率分布理论，深入揭示特征空间优化与模型性能的内在联系。综上所述，本章研究为神经网络的不确定性建模和特征空间优化提供了有力支持，为后续研究和实际应用奠定了坚实基础。

本文围绕神经网络模型的不确定性建模展开研究，首先综述了当前主流的不确定性建模方法，包括贝叶斯神经网络、模型集成、测试时数据增强以及单一确定性神经网络方法，并分析了各自的优缺点。贝叶斯神经网络、模型集成及测试时数据增强方法在计算复杂度较高，建模效率相对较低，为了更高效地建模神经网络的不确定性，本文将研究重心放在了单一确定性-建模方法上，重点探讨了如何在高维特征概率密度估计的框架下提升不确定性建模的效果。针对现有方法在模型不确定性建模效果上的局限性，本文提出了两种改进方法：

其一是基于输入扰动的改进策略：本文发现分布内样本与分布外样本在梯度空间中存在显著差异，分布外样本的梯度响应更大，并通过理论分析对此现象进行了理论上的分析。基于这一结论，提出了引入梯度相关扰动的方法，以增强两类样本在概率密度分布上的差异性。实验结果表明，该策略在OOD检测、对抗样本识别等任务中显著提升了模型不确定性的建模效果。

其二是基于联合训练的改进策略：本文分析了特征空间结构对不确定性建模效果的影响，指出提升类内紧密性和类间可分性有助于提高基于高维特征概率密度估计的模型不确定性建模能力。为此，本文设计了一种全新的辅助损失函数，并结合交叉熵损失进行联合训练，以优化特征空间结构。实验结果表明，该方法能够在不同任务上显著提升模型不确定性建模的性能。此外，为降低高维特征带来的存储开销，本文提出利用主成分分析（PCA）进行降维，不仅减少存储需求，同时提高了建模效率和效果。

本文的主要贡献总结如下：
\begin{itemize}
    \item 发现并解释了分布外样本在梯度空间上的响应更大，分布内样本在梯度空间上的响应更小。
    \item 提出基于梯度的输入扰动策略，以提升基于概率密度估计的模型不确定性建模的效果。
    \item 设计新的辅助损失函数，提高特征空间的类内紧密性和类间可分性，从而提升基于概率密度估计的模型不确定性的建模效果。
    \item 采用PCA降维，降低存储复杂度，同时提升建模效率。
\end{itemize}

尽管本文在神经网络不确定性建模方面取得了一定进展，但仍存在以下值得进一步探讨的问题：

\begin{itemize}
    \item 计算复杂度与实时性问题： 虽然本文提出的方法在一定程度上提升了不确定性建模的精度，但计算梯度信息及特征优化仍然带来了额外的计算开销。在计算资源受限的环境（如嵌入式系统）中，如何进一步降低计算成本，同时保持良好的不确定性量化能力，是未来研究的重要方向。
    
    \item 方法的泛化性： 本文的研究主要围绕图像分类任务展开，然而，基于高维特征概率密度估计的建模不确定性的方法是否适用于其他任务（如目标检测、语义分割、自然语言处理等）仍需进一步验证。此外，不同神经网络架构对本文方法的适应性仍需深入探索，未来可进一步研究如何将所提出的策略推广到更广泛的深度学习应用场景。

    \item 全面的不确定性建模框架： 目前的不确定性量化方法主要依赖概率密度估计，而不确定性本质上是一个复杂概念，可能涉及数据噪声、模型结构及训练数据分布等多个因素。未来研究可考虑结合其他不确定性建模方法（如贝叶斯推断、信息论度量等），构建更加全面的不确定性量化框架。

    \item 理论分析的深入性： 本文通过实验和部分理论推导验证了所提出方法的有效性，但仍需更深入的数学分析，以更严格地刻画输入扰动、特征优化与不确定性量化之间的关系。此外，研究不同数据集、不同模型架构下的方法泛化性，并建立相应的理论框架，是未来研究的重要方向。
\end{itemize}

综上所述，本文针对单一确定性神经网络的不确定性建模问题，提出了两种基于高维特征概率密度估计的改进策略，并在多个任务上验证了其有效性。然而，在计算效率、泛化性及理论分析方面仍有进一步优化的空间。

\section{对神经网络不确定性研究的展望}

随着深度学习的广泛应用，神经网络的不确定性研究在模型安全性、鲁棒性和可靠性等领域展现出重要价值，未来对不确定性的研究可以从以下几个方面展开。

现有的不确定性建模方法，如贝叶斯神经网络和深度集成方法，往往面临计算成本高和难以扩展的问题。未来研究可以关注开发计算效率更高的模型，适用于大规模数据集和实时应用，构建能够同时捕获数据不确定性和模型不确定性的统一建模框架。

当前对不确定性模型的评估依赖于间接任务（如 OOD 检测），难以全面反映实际性能。未来可以探索真实任务驱动评估，设计更加贴近实际应用的不确定性评估任务。结合模型性能、不确定性分布的合理性和计算效率，建立综合评估体系。

随着任务复杂度增加，未来不确定性建模需要适配新的应用场景，例如：多模态数据，探索图像、文本和音频等多模态数据的不确定性建模方法。在线学习与自适应系统，开发能动态调整不确定性的模型，适应在线学习和环境变化。

近年来，大规模预训练模型GPT3\cite{brown2020language}、BERT\cite{devlin2019bert}、BLOOM\cite{scao2022bloom}等在多个领域取得显著进展。不确定性研究未来可以聚焦于预训练与微调阶段的不确定性，研究大规模模型在不同训练阶段中的不确定性特性，开发针对大规模模型的不确定性标定方法，分析大规模预训练模型在迁移学习和跨领域任务中的不确定性。

神经网络不确定性研究作为机器学习的重要方向，未来将进一步推动 AI 系统的可靠性与广泛应用。随着理论方法的深入发展和新兴应用场景的拓展，不确定性建模将成为构建智能、透明和可信 AI 系统的核心技术之一。



